
<br />

<p align="center">
  <img src="./misc/alstm-logo-yellow.svg" alt="alstm-logo" width="550px" />
</p>

<p align="center">  
  <a href="https://www.python.org/">
    <img src="https://img.shields.io/badge/Python%203.11-3776AB?style=for-the-badge&logo=python&logoColor=yellow&color=3776AB" alt="python-badge" />
  </a>
  <a href="https://www.tensorflow.org/">
    <img src="https://img.shields.io/badge/TensorFlow%202.14-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" alt="tensoflow-badge" />
  </a>
  <a href="https://www.ibm.com/products/cloudant">
    <img src="https://img.shields.io/badge/IBM%20Cloudant-1261FE?style=for-the-badge&logo=IBM%20Cloud&logoColor=white" alt="python-badge" />
  </a>
</p>

<br />

<p align="center">
Projeto desenvolvido como <b>Trabalho de Conclus√£o de Curso</b> durante o √∫ltimo ano de gradua√ß√£o em <b>Engenharia Mecatr√¥nica</b> na Escola Polit√©cnica da Universidade de S√£o Paulo (EP-USP)
</p>

<br />

## üîé Sum√°rio

Neste reposit√≥rio:

* <a href="#-sobre">üìú Sobre</a> - Breve apresenta√ß√£o

* <a href="#-problem√°tica--motiva√ß√£o">‚ÅâÔ∏è Problem√°tica & Motiva√ß√£o</a> - Porqu√™s e objetivos

* <a href="#-dados--pre-processamento">‚öôÔ∏è Dados & Pr√©-Processamento</a> - Pipeline de dados

* <a href="#-otimiza√ß√£o">ü¶æ Otimiza√ß√£o</a> - Ajuste dos hiperpar√¢metros

* <a href="#-rede--treinamento">üß† Rede & Treinamento</a> - Arquitetura implementada

* <a href="#-resultados">üìà Resultados</a> - Desempenho do modelo

* <a href="#-aplica√ß√£o">üåé Aplica√ß√£o</a> - Visualiza√ß√£o pr√°tica

* <a href="#-uso--c√≥digo">üë®‚Äçüíª Uso & C√≥digo</a> - Orienta√ß√µes gerais

* <a href="#-colaboradores">ü§ù Colaboradores</a> - Equipe envolvida


## üìú Sobre

> *History never repeats itself, but it does often rhyme*  
> [Mark Twain](https://pt.wikipedia.org/wiki/Mark_Twain)

Este reposit√≥rio cont√©m o c√≥digo do estudo sobre a **previs√£o do √≠ndice S&P 500**, no qual foi desenvolvido um modelo utilizando **c√©lulas de mem√≥ria de longo-curto prazo (LSTM) combinadas com mecanismos de aten√ß√£o**. O modelo passou por otimiza√ß√µes com t√©cnicas de Grid Search e Bayesian Seach, demonstrando um desempenho promissor na previs√£o de pre√ßos de fechamento.

O trabalho foi majoritariamente inspirado no artigo **[Forecasting stock prices with long-short term memory neural network based on attention mechanism](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0227222)** (2020) de Jiayu Qiu, Bin Wang e Changjun Zhou, recebendo honras como um dos cinco melhores projetos de 2023 no curso.

No estudo tamb√©m foram exploradas aplica√ß√µes mais pr√°ticas do modelo atrav√©s de t√©cnicas de gest√£o de banca, avaliando a rentabilidade das previs√µes em um ambiente controlado e com resultados igualmente promissores.

#### üìï **[Vers√£o final da monografia](https://github.com/gvmossato/alstm-stock-market/blob/main/misc/Previs%C3%A3o%20do%20%C3%8Dndice%20S%26P%20500%20Utilizando%20LSTM%20e%20Mecanismos%20de%20Aten%C3%A7%C3%A3o.pdf)**

## ‚ÅâÔ∏è Problem√°tica & Motiva√ß√£o

O aprofundamento financeiro do Brasil, marcado pela liberaliza√ß√£o, desregulamenta√ß√£o e inova√ß√£o, catalisou um aumento expressivo no n√∫mero de participantes do mercado financeiro, incluindo tamb√©m pequenas gestoras e investidores individuais. Entretanto, esse crescimento acompanha tamb√©m uma ascens√£o da desinforma√ß√£o, exacerbada pela vulnerabilidade √† fraude e pela difus√£o de an√°lises de fontes n√£o especializadas.

<p align="center"> 
  <img src="https://i.ibb.co/BjvJbqq/decision-making-process.png" alt="decision-making-process" height="190px" />
  <span>¬†¬†¬†¬†¬†¬†¬†</span>
  <img src="https://i.ibb.co/XkNtbC2/fraud.png" alt="fraud" height="190px" />
</p>

Em paralelo, entende-se que a economia global √©, de certo modo, refletido pelo √≠ndice S&P 500 devido √† vasta opera√ß√£o internacional das empresas listadas nesse. Tal cen√°rio abre espa√ßo para que modelos preditivos possam empoderar o processo de tomada de decis√£o de investimentos, especialmente para aqueles rec√©m-chegados ao mercado.

Assim, a motiva√ß√£o desse trabalho reside na necessidade de fortalecer o processo decis√≥rio no contexto complexo e vol√°til do mercado de a√ß√µes. O modelo proposto busca ser uma ferramenta auxiliar, n√£o substituindo, mas sim potencializando o racioc√≠nio estrat√©gico de investidores. Para tal, os recentes desenvolvimentos em mecanismos de aten√ß√£o em redes neurais s√£o aplicados aqui √†s s√©ries temporais financeiras oferecendo aos investidores, especialmente aqueles com recursos limitados e acesso tardio a informa√ß√µes, uma fonte a mais para suas decis√µes.

## ‚öôÔ∏è Dados & Pr√©-Processamento

Fluxograma simplificado do pr√©-processamento dos dados at√© serem consumidos pelo modelo:

![dados](https://i.ibb.co/tmhPnPk/dados.png)

Conforme a imagem:

1. **Fonte:** o conjunto de dados utilizado nesse projeto √© um recorte hist√≥rico abrangendo de 03 de janeiro de 1983 a 01 de setembro de 2023, retirado do Yahoo! Finance.

2. **Redu√ß√£o de Ru√≠do:** [transformada wavelet](https://towardsdatascience.com/the-wavelet-transform-e9cfa85d7b34) com a fam√≠lia de fun√ß√µes Coiflets at√© terceira ordem, a qual √© particularmente eficaz na redu√ß√£o de ru√≠do em sinais n√£o estacion√°rios como os de pre√ßos de a√ß√µes.

3. **Normaliza√ß√£o:** para assegurar que todas as vari√°veis tenham o mesmo peso durante o treinamento da rede, aplicamos a normaliza√ß√£o [Z-Score](https://www.statology.org/z-score-normalization/). Isso coloca todas as vari√°veis na mesma escala, neutralizando o efeito de disparidades nas magnitudes de pre√ßos e volumes transacionais.

4. **Reparti√ß√£o:** os dados s√£o divididos em tr√™s segmentos: treino, valida√ß√£o e teste, na propor√ß√£o de 95/2.5/2.5. Escolhemos essa divis√£o para permitir um ajuste fino dos hiperpar√¢metros (usando o conjunto de valida√ß√£o) e uma avalia√ß√£o honesta do desempenho do modelo (usando o conjunto de teste). Ao manter a ordem temporal (sem embaralhamento), respeitamos a sequ√™ncia natural dos eventos no mercado de a√ß√µes.

5. **Janelamento:** implementamos uma t√©cnica de janela deslizante com tamanho de 20 dias (aproximadamente um m√™s em dias √∫teis), que constitui o passo temporal do nosso modelo. Dentro dessa janela, seis s√©ries temporais distintas ‚Äî abertura, fechamento, m√°xima, m√≠nima, [fechamento ajustado](https://help.yahoo.com/kb/SLN28256.html) e volume (em quantidades) ‚Äî s√£o fornecidas ao modelo. Com esses dados ele prediz o valor de fechamento no vig√©simo primeiro dia.

## ü¶æ Otimiza√ß√£o

Como citado, realizamos a tunagem de hiperpar√¢metros em duas fases distintas: um Grid Search e Bayesian Search. No primeiro, buscamos explorar deterministicamente as redondezas do modelo apresentado no artigo base utilizado. Assim, com um total de **48 combina√ß√µes √∫nicas** de hiperpar√¢metros avaliadas utilizando a metodologia de [valida√ß√£o cruzada com k-dobras](https://medium.com/@soumyachess1496/cross-validation-in-time-series-566ae4981ce4) obtivemos **144 execu√ß√µes distintas** (k=3).

Na sequ√™ncia, o Bayesian Search foi implementado com base nas combina√ß√µes de hiperpar√¢metros mais promissoras do Grid Search, em uma tentativa de refinar a rede. Nesse ponto, decidimos fixar o tamanho do estado oculto em 20, baseando-nos nas descobertas do Grid Search e na sintonia com o tamanho de entrada de dados (20 dias √∫teis). Ao longo de **100 configura√ß√µes** de redes, avaliamos e validamos diferentes modelos, totalizando **300 execu√ß√µes**.

Um resumo dos testes encontra-se na tabela abaixo:

| Hiperpar√¢metro | Grid Search | Bayesian Search |
|----------------|-------------|-----------------|
| Tamanho do Estado Oculto | 10, 20, 50, 100 | N√£o testado |
| Taxa de Aprendizado | 0,001; 0,01; 0,1 | 0,0001 a 0,01 |
| Tamanho do Lote | 64, 128, 256, 512 | 64, 128, 256, 512, 1024 |
| Taxa de Dropout | N√£o testado | 0% a 30% |

## üß† Rede & Treinamento

A arquitetura proposta para o modelo de previs√£o do √≠ndice S&P 500 incorpora um total de **20 c√©lulas LSTM**, em conson√¢ncia com a janela de 20 dias que √© analisada. Isto √©, para uma janela m√≥vel de 20 dias, s√£o lidos [OHLC](https://www.investopedia.com/terms/o/ohlcchart.asp) + Fechamento Ajustado + Volume (quantidades), para ent√£o predizer o fechamento do 21¬∫ dia.

![modelo](https://i.ibb.co/jk7DVzR/modelo.png)

Como msotra imagem anterior, ap√≥s o processamento pelas c√©lulas LSTM, as sa√≠das s√£o submetidas ao mecanismo de *[soft attention](https://stackoverflow.com/questions/35549588/soft-attention-vs-hard-attention)*. Esse mecanismo avalia as contribui√ß√µes de cada c√©lula LSTM e pondera sua influ√™ncia, permitindo que a import√¢ncia de momentos distintos no tempo seja diferenciada, ao inv√©s de focar apenas na informa√ß√£o mais recente. Isso se baseia na premissa de que eventos passados dentro da janela de tempo podem ter relev√¢ncia semelhante ou at√© maior do que os mais recentes.

A "camada de aten√ß√£o" ent√£o agrega as sa√≠das das c√©lulas LSTM ponderadas em um vetor de contexto que concentra as informa√ß√µes relevantes detectadas pela rede. Esse vetor de contexto √© ent√£o passado por uma camada de [dropout](https://towardsdatascience.com/dropout-in-neural-networks-47a162d621d9#waht-is-a-dropout), com uma taxa de desativa√ß√£o de 12,241%, antes de ser apresentado √† √∫ltima camada da rede.

A fase final da arquitetura √© composta por uma camada densa com um √∫nico neur√¥nio, cuja **fun√ß√£o de ativa√ß√£o linear** √© adequada para tarefas de regress√£o como a previs√£o de √≠ndices de a√ß√µes. Esse neur√¥nio processa o vetor e produz o output final da rede: a previs√£o do valor de fechamento do S&P 500.

Por fim, o treinamento da rede ocorre ao longo de **2000 epochs** com um **batch size de 128**. O algoritmo **[ADAM](https://medium.com/@LayanSA/complete-guide-to-adam-optimization-1e5f29532c3d)** √© o escolhido para otimiza√ß√£o, operando com uma **taxa de aprendizado de 0,00018** - esses par√¢metros foram selecionados com base nos resultados da busca em grid, da busca bayesiana e da an√°lise da curva de aprendizado.

## üìà Resultados

A se√ß√£o de resultados se prolonga por algumas dezenas de p√°ginas da monografia, ent√£o, n√£o sendo pertinente trazer todos os resultados, abordamos aqui um recorte conveniente do que alcan√ßamos com o modelo.

Qualitativamente, os resultados no conjunto de teste e o retorno acumulado ao longo do per√≠odo s√£o bastante fidedignos ao que se observou no mercado para √† √©poca:

<p align="center">
  <img src="https://i.ibb.co/71mF1gB/test-results.png" alt="test-results" width="350px" />
  <span>¬†¬†¬†¬†¬†¬†¬†</span>
  <img src="https://i.ibb.co/mhkQhh6/return-results.png" alt="return-results" width="350px" />
</p>

Optamos ainda por fazer um estudo comparativo do mecanismo de aten√ß√£o, testando varia√ß√µes desse: um rede sem aten√ß√£o, uma rede com a aten√ß√£o como proposta no artigo de refer√™ncia (benchmark) e a "aten√ß√£o cl√°ssica", proposta no artigo inaugural [Attention Is All You Need](https://arxiv.org/abs/1706.03762):

<p align="center">
  <img src="https://i.ibb.co/TkDq633/attention-results.png" alt="attention-results" width="900px" />
</p>

√â observ√°vel, portanto, a influ√™ncia e consequente melhora do desempenho do modelo com o uso do mecanismo cl√°ssico. Quando passamos, todavia, a avaliar quantitativamente o modelo frente ao benchmark, encontramos um problema inicial:

|                  | Benchmark    | Modelo         |
|------------------|--------------|----------------|
| Data m√≠nima (teste) | 2019-05-17   | 2022-09-23  |
| Data m√°xima (teste) | 2019-07-01   | 2023-09-01  |
| Observa√ß√µes        | 31           | 237          |
| Pre√ßo M√≠nimo       | 2751,53      | 3577,03      |
| Pre√ßo M√°ximo       | 2971,41      | 4588,96      |
| Amplitude de Pre√ßos| 219,88       | 1011,93      |
| Pre√ßo M√©dio        | 2870,27      | 4095,33      |
| Volatilidade Anualizada | 11,28%  | 17,58%       |

Como sintetiza a tabela anterior, o conjunto de teste do nosso modelo encontrava-se em um mercado muito mais complexo: mais observa√ß√µes com maiores amplitudes de pre√ßo e uma volatilidade notadamente superior. Assim, a compara√ß√£o direta n√£o poderia ser considerada justa, optamos ent√£o por normalizar a compara√ß√£o das m√©tricas de erro por dois m√©todos, pre√ßo m√©dio e amplitude:

|                        | Benchmark    | Modelo       |
|------------------------|--------------|--------------|
| **M√©tricas**           |              |              |
| RMSE                   | 0,3475       | 19,5238      |
| MAE                    | 0,1935       | 13,9011      |
| $R^2$                  | 0,8783       | 0,9940       |
| **Normaliza√ß√£o pelo Pre√ßo M√©dio** |   |              |
| RMSE                   | 0,00012107   | 0,00476734   |
| MAE                    | 0,00006742   | 0,00339437   |
| **Normaliza√ß√£o pela Amplitude de Pre√ßos** | |        |
| RMSE                   | 0,00158041   | 0,01929363   |
| MAE                    | 0,00088003   | 0,01373717   |

Todavia, mesmo ap√≥s a normaliza√ß√£o, com exce√ß√£o do $R^2$, n√£o superamos o benchmark. N√£o obstante, esses resultados forneceram um *insight* valioso: embora n√£o estejamos acertando adequadamente o pre√ßo de fechamento, estamos fazendo uma leitura muito satisfat√≥ria da tend√™ncia. Ora, vamos ent√£o aprofundar essa an√°lise:

<p align="center">
  <img src="https://i.ibb.co/C77TdZZ/trend-results.png" alt="trend-results" width="350px" />
  <span>¬†¬†¬†¬†¬†¬†¬†</span>
  <img src="https://i.ibb.co/Fz7XPkn/confusion-matrix.png" alt="confusion-matrix" width="350px" />
</p>

Constatamos que o modelo de fato parece seguir muito bem as oscila√ß√µes, prevendo com consist√™ncia quando o mercado ir√° subir ou cair:

* Dado que o √≠ndice subiu, acertamos **84,72%** das vezes.
* Dado que o √≠ndice caiu, acertamos **80,43%** das vezes.

Frente a esses resultados, optamos ent√£o por tentar validar o modelo em uma abordagem um pouco mais pr√°tica, donde surge a iniciativa de aplicar estrat√©gias de gest√£o de banca para operar no mercado tendo em vista as previs√µes. Foram exploradas diversas estrat√©gias (Martingale, Paroli, D'Alembert, etc.) em um ambiente simulado simplificado, cujas hip√≥teses foram:

1. Livre de custos
2. Liquidez e volume suficientes no mercado
3. Opera√ß√µes ao pre√ßo de fechamento
4. Sem alavancagem
5. **Compra e *short selling* s√£o igualmente complexos**

Destarte, mediante a previs√£o do modelo e a estrat√©gia de gest√£o escolhida, o investidor entra comprado ou vendido no ativo, ganhando ou perdendo consoante a varia√ß√£o do √≠ndice no per√≠odo. Os resultados para uma das estrat√©gias mais rent√°veis ‚Äî Paroli ‚Äî pode ser visto no gr√°fico abaixo:

<p align="center">
  <img src="https://i.ibb.co/0KZDTdk/paroli-results.png" alt="paroli-results" width="600px" />
</p>

Finalmente, como um todo, o quadro de resultados da gest√£o de banca fica expresso por:

<p align="center">
  <img src="https://i.ibb.co/DYxjYSs/bet-results.png" alt="bet-results" width="700px" />
</p>

## üåé Aplica√ß√£o

Como um todo, a implementa√ß√£o do projeto pode ser segmentada entre duas grandes frentes: o **modelo**, que compreende basicamente a tudo que fora exposto at√© aqui, como a rede, o treinamento, as valida√ß√µes t√©cnicas e pr√°ticas, etc. Em paralelo, existe ainda a **aplica√ß√£o**: uma plataforma web, hospedada em um outro [reposit√≥rio dedicado](https://github.com/gvmossato/alstm-front), para proporcionar uma interface intuitiva o suficiente a fim de permitir que usu√°rios comuns pudessem usufruir das predi√ß√µes do modelo sem conhecimento t√©cnico em programa√ß√£o.

A aplica√ß√£o permaneceu operante at√© meados de abril de 2024, sendo incorporados os dados mais recentes dispon√≠veis √† √©poca a cada **seis meses**, em treinamentos incrementais autom√°ticos com **15 epochs** e integra√ß√£o ao [IBM Cloudant](https://www.ibm.com/br-pt/products/cloudant), provedor do banco de dados NoSQL utilizado.

## üë®‚Äçüíª Uso & C√≥digo

Para executar o **modelo** e definir op√ß√µes espec√≠ficas de ajuste de par√¢metros e carregamento de pesos de sess√µes de treinamento anteriores (se necess√°rio), utilize:

```css
poetry run model [-t {grid,bayes}] [-w]
```

Par√¢metros opcionais:

* `-t`, `--tuning`: especifica o m√©todo de otimiza√ß√£o a ser executado. Se n√£o especificado, o ajuste de par√¢metros n√£o ser√° realizado. As configura√ß√µes para cada tipo de ajuste devem ser definidas diretamente no c√≥digo. Aceita:

  * `grid`: utiliza o Grid Search para otimizar os par√¢metros.

  * `bayes`: utiliza o Bayesian Search para otimizar os par√¢metros.

* `-w`, `--load-weights`: carrega os pesos salvos da sess√£o de treinamento mais recente.

  * Padr√£o: `False` (n√£o carrega os pesos automaticamente).

<br />

Para executar a **aplica√ß√£o** para realizar previs√µes com os dados mais recentes dispon√≠veis, sincroniza√ß√£o com a nuvem e treinamentos incrementais (se necess√°rio), utilize:

```
poetry run app
```

Note que para integra√ß√£o com o banco de dados ser√° necess√°rio especificar as var√°veis de ambiente requeridas pelo servi√ßo de nuvem: `DATABASE`, `CLOUDANT_USERNAME`, `CLOUDANT_PASSWORD` e `CLOUDANT_HOST`.

***

Em rela√ß√£o ao c√≥digo, a √°rvore de arquivos do projeto est√° organizada como:

```
üì¶alstm_stock_market
 ‚î£ üìÇimages
 ‚î£ üìÇlogs
 ‚î£ üìÇsrc
 ‚îÉ ‚î£ üìÇapp
 ‚îÉ ‚îÉ ‚îó üìúapp.py
 ‚îÉ ‚î£ üìÇdata
 ‚îÉ ‚îÉ ‚îó üìúpreprocessor.py
 ‚îÉ ‚î£ üìÇhelpers
 ‚îÉ ‚îÉ ‚î£ üìÇcalendars
 ‚îÉ ‚îÉ ‚îÉ ‚îó üìúus.cal
 ‚îÉ ‚îÉ ‚î£ üìúplotter.py
 ‚îÉ ‚îÉ ‚îó üìúutils.py
 ‚îÉ ‚î£ üìÇmanager
 ‚îÉ ‚îÉ ‚î£ üìúmanager.py
 ‚îÉ ‚îÉ ‚îó üìústrategies.py
 ‚îÉ ‚î£ üìÇmodel
 ‚îÉ ‚îÉ ‚î£ üìÇweights
 ‚îÉ ‚îÉ ‚î£ üìúevaluator.py
 ‚îÉ ‚îÉ ‚î£ üìúmodel.py
 ‚îÉ ‚îÉ ‚îó üìúparams.py
 ‚îó üìúrun.py
```

Ela est√° dividida em m√≥dulos que concentram as distintas opera√ß√µes do c√≥digo:

* `üìÇsrc/model/`: cont√©m os arquivos referentes ao modelo em si, como arquitetura, hiperpar√¢metros da rede e m√©tricas de avalia√ß√£o. Na subpasta `weights` encontram-se os arquivos `.h5` com os pesos do modelo ap√≥s treinamentos.

* `üìÇsrc/app/`: cont√©m a l√≥gica que permite ao modelo ser executado em produ√ß√£o, conforme trabalhado na se√ß√£o "Aplica√ß√£o". As rotinas de treinamentos incrementais e comunica√ß√£o com a nuvem (IBM Cloudant) encontram-se aqui.

* `üìÇsrc/manager/`: cont√©m os arquivos referentes √† gest√£o de banca. Subdivis√£o do c√≥digo implementada para avaliar o desempenho do modelo em um cen√°rio ainda controlado, mas mais pr√≥ximo da pr√°tica, operando com distintas estrat√©gias frente √†s previs√µes.

* `üìÇsrc/data/`: cont√©m os arquivos referentes a todo o pipeline de dados exposto, capaz de lidar com cada um dos casos de uso esperados (treinamento inicial, treinamentos adicionais, uso em produ√ß√£o, etc.).

* `üìÇsrc/helpers/`: cont√©m os arquivos gerais e de uso compartilhado entre os demais m√≥dulos, fun√ß√µes e m√©todos auxiliares.

<br />

Por fim, a pasta `images` √© utilizada para salvar os plots em formatados vetorizados, se desej√°vel, enquanto `logs` armazena registros de execu√ß√£o do m√≥dulo de aplica√ß√£o.

## ü§ù Colaboradores

Este projeto foi desenvolvido por [Gabriel Mossato](https://br.linkedin.com/in/gvmossato) em colabora√ß√£o com [Paulino Fonseca](https://br.linkedin.com/in/paulinoveloso), ambos √† √©poca graduandos sob orienta√ß√£o do [Prof. Dr. Oswaldo Luiz do Valle Costa](https://bv.fapesp.br/en/pesquisador/191/oswaldo-luiz-do-valle-costa), pertencente ao Departamento de Engenharia El√©trica da Escola Polit√©cnica da Universidade de S√£o Paulo (EP-USP).
